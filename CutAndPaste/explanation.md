# Cut and Paste

Problem statement can be found [here](https://cses.fi/problemset/task/2072/).

A naive approach to this problem would take O(n) time complexity per each query, which would be O(nm). Since each of these variables can be 2*10^5 = 200000, this would be too slow for competitive programming.

To come up with a faster algorithm, we will use a structure called [Treap](https://en.wikipedia.org/wiki/Treap). Basically, a treap is a tree combined with a heap (that's where the name comes from). It's a binary tree in which we store values inside nodes in some order. The twist is that every node has a *priority* sorted randomly at initialization, and then the nodes are arranged in a way that, if we only look at the priorities, the tree is a heap. Since the priority is sorted at random, statistically the tree won't end up being too unbalanced, making the queries to the tree O(logn) *average-case* time complexity.

This structure comes as an alternative to AVL trees in competitive programming because, although we trade an O(logn) worst-case time complexity for an O(logn) average-case complexity, the treaps are quite easy to implement, allowing us to implement the whole structure in a reasonable time during competition. In use cases where we just have to use the standard queries such as insert, search and delete elements in the tree, we can just use a library implementation of an AVL tree, but in problems like this one sometimes we need to dive inside the structure, make some structural changes, or maybe build the structure from scratch. That's when the advantage of the treaps comes into play.

Overall, the way we construct and operate with treaps is by using two methods: split and merge. Split receives a treap and a value and returns two treaps: the treap that contains the values below the given parameter, and the treap with the values above the given value. Merge receives two treaps and returns another treap that contains the nodes of both given treaps respecting their values ordering and priorities.

In this problem, each node will contain a character of the string and, at all times, the order of the characters in the treap will be the order of the string at that moment after doing the desired queries. The modification we will make to the original structure is that we will use implicit keys. This means that we are going to store the size of each subtree in order to efficiently compute the index of one particular node in the order given by the tree. That way we will be able to perform the operation "split the treap at the first k nodes".

So in this particular treap, the values will not determine the order of the nodes, but the opposite: the order of the nodes will determine the order in which we will return the values (i.e. the characters of the string) at the end of the execution.

With all this machinery, we can easily perform a query in O(logn) average-case time complexity like so: If we are asked to cut the string between *a* and *b*, we can split the tree at *b*, leaving us with two treaps, say T\_1 and T\_right, where T\_1 contains the first *b* characters and T\_right the last *n-b* characters. Then, we split T\_1 at *a-1*, leaving us with another two treaps T\_left and T\_middle, where T\_left contains the first *a-1* values and T\_middle contains the values between *a* and *b*. Lastly, we merge these three treaps in the correct order, which is T\_left ---> T\_right ---> T\_middle (which would be the "paste" part of the query). Split and merge do all the work for us. And since both are recursive functions in the depth of the tree (which should be fairly balanced), they have an O(logn) average-case time complexity, making the algorithm viable.

There are two last details to talk about in this implementation: The methods "evaluate" and "heapify". the "evaluate" function is the one that keeps updated the attribute of each node that stores the size of its subtree. And "heapify" is used when constructing the treap at the beginning of execution. Since the order is already determined by the starting string, instead of just using the random priorities to determine the distribution of the nodes we initialize a balanced tree, and then rearrange the priorities (heapify) in order to meet the heap condition.
